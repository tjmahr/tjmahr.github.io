---
title: "sample_n_of(): a useful helper function"
excerpt: Randomly sampling subsets of data
tags:
  - r
  - nonstandard evaluation
  - dplyr
  - babynames
share: true
header:
  overlay_image: "assets/images/marisa-morton-1280.jpg"
  image_description: "A wall of donuts"
  overlay_filter: rgba(10, 10, 10, 0.1)
  caption: "Photo credit: [**Marisa Morton**](https://unsplash.com/photos/Rtr7JeG4too/info)"
---

```{r setup, include = FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

Here's the problem: I have some data with nested time series. Lots of
them. It's like there's many, many little datasets inside my data. There
are too many groups to plot all of the time series at once, so I just
want to preview a handful of them.

For a working example, suppose we want to visualize the top 50 American
female baby names over time. I start by adding up the total number of
births for each name, finding the overall top 50 most populous names,
and then keeping just the time series from those top names.

```{r}
library(ggplot2)
library(dplyr, warn.conflicts = FALSE)

babynames <- babynames::babynames %>% 
  filter(sex == "F")

top50 <- babynames %>% 
  group_by(name) %>% 
  summarise(total = sum(n)) %>% 
  top_n(50, total) 

# keep just rows in babynames that match a row in top50
top_names <- babynames %>%
  semi_join(top50, by = "name")
```

Hmm, so what does this look like?

```{r overplotted, fig.cap = "An illegible plot because too many facets are plotted"}
ggplot(top_names) + 
  aes(x = year, y = n) + 
  geom_line() + 
  facet_wrap("name")
```

Aaack, I can't read anything! Can't I just see a few of them?

This is a problem I face frequently, so frequently that I wrote a helper
function to handle this problem: `sample_n_of()`. This is not a very
clever name, but it works. Below I call the function from my personal R
package and plot just the data from four names.

```{r sample-plot, fig.cap = "A plot with four faceted timeseries"}
# For reproducible blogging
set.seed(20180524)

top_names %>% 
  tjmisc::sample_n_of(4, name) %>% 
  ggplot() + 
    aes(x = year, y = n) + 
    geom_line() + 
    facet_wrap("name")
```

In this post, I walk through how this function works. It's not very
complicated: It relies on some light tidy evaluation plus one obscure
dplyr function.

## Working through the function

As usual, let's start by sketching out the function we want to write:

```{r, eval = FALSE}
sample_n_of <- function(data, size, ...) {
  # quote the dots
  dots <- quos(...)
  
  # ...now make things happen...
}
```

where `size` are the number of groups to sample and `...` are the
columns names that define the groups. We use `quos(...)` to capture and
quote those column names. ([As I wrote
before](/set-na-where-nonstandard-evaluation-use-case/), quotation is
how we bottle up R code so we can deploy it for later.)

For interactive testing, suppose our dataset are the time series from
the top 50 names and we want data from a sample of 5 names. In this
case, the values for the arguments would be:

```{r}
data <- top_names
size <- 5
dots <- quos(name)
```

A natural way to think about this problem is that we want to sample
subgroups of the dataframe. First, we create a grouped version of the
dataframe using `group_by()`. The function `group_by()` also takes a
`...` argument where the dots are typically names of columns in the
dataframe. We want to take the names inside of our `dots`, unquote them
and plug them in to where the `...` goes in `group_by()`. This is what
the tidy evaluation world calls
[*splicing*](https://dplyr.tidyverse.org/articles/programming.html#unquote-splicing).

Think of splicing as doing this:

```{r}
# Demo function that counts the number of arguments in the dots
count_args <- function(...) length(quos(...))
example_dots <- quos(var1, var2, var2)

# Splicing turns the first form into the second one
count_args(!!! example_dots)
count_args(var1, var2, var2)
```

So, we create a grouped dataframe by splicing our dots into the
`group_by()` function.

```{r}
grouped <- data %>% 
  group_by(!!! dots)
```

There is a helper function buried in dplyr called `group_indices()`
which returns the grouping index for each row in a grouped dataframe.

```{r}
grouped %>% 
  tibble::add_column(group_index = group_indices(grouped)) 
```

We can randomly sample five of the group indices and keep the rows for
just those groups.

```{r}
unique_groups <- unique(group_indices(grouped))
sampled_groups <- sample(unique_groups, size)
sampled_groups

subset_of_the_data <- data %>% 
  filter(group_indices(grouped) %in% sampled_groups)
subset_of_the_data

# Confirm that only five names are in the dataset
subset_of_the_data %>% 
  distinct(name)
```

Putting these steps together, we get:

```{r}
sample_n_of <- function(data, size, ...) {
  dots <- quos(...)
  
  group_ids <- data %>% 
    group_by(!!! dots) %>% 
    group_indices()
  
  sampled_groups <- sample(unique(group_ids), size)
  
  data %>% 
    filter(group_ids %in% sampled_groups)
}
```

We can test that the function works as we might expect. Sampling 10
names returns the data for 10 names.

```{r}
ten_names <- top_names %>% 
  sample_n_of(10, name) %>% 
  print()

ten_names %>% 
  distinct(name)
```

We can sample based on multiple columns too. Ten combinations of names
and years should return just ten rows.

```{r}
top_names %>% 
  sample_n_of(10, name, year) 
```

## Next steps

There are a few tweaks we could make to this function. For example, in
my package's version, I warn the user when the number of groups is too
large.

```{r}
too_many <- top_names %>% 
  tjmisc::sample_n_of(100, name)
```

My version also randomly samples *n* of the rows when there are no
grouping variables provided.

```{r}
top_names %>% 
  tjmisc::sample_n_of(2)
```

One open question is how to handle data that's already grouped. The
function we wrote above fails. 

```{r}
top_names %>% 
  group_by(name) %>% 
  sample_n_of(2, year)
```

Is this a problem?

Here I think failure is okay because what do we think should happen?
It's not obvious. It should randomly choose 2 of the years for each
name. Should it be the same two years? Then this should be fine.

```{r}
top_names %>% 
  sample_n_of(2, year)
```

Or, should those two years be randomly selected for each name? Then, we
should let `do()` handle that. `do()` takes some code that returns a
dataframe, applies it to each group, and returns the combined result.

```{r}
top_names %>% 
  group_by(name) %>% 
  do(sample_n_of(., 2, year))
```

I think raising an error and forcing the user to clarify their code is a
better than choosing one of these options and not doing what the user
expects.

```{r, include = FALSE}
.parent_doc <- knitr::current_input()
```
```{r, child = "_R/_footer.Rmd"}
```

