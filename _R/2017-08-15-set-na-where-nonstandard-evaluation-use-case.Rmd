---
title: "set_na_where(): a nonstandard evaluation use case"
excerpt: Bottling up magic spells
tags:
  - r
  - nonstandard evaluation
  - eyetracking
  - rlang
share: true
header:
  overlay_image: "assets/images/jovi-waqa-1280.jpg"
  caption: "Photo credit: [**Jovi Waqa**](https://unsplash.com/photos/gNJn5-C5enE)"
---

```{r, include = FALSE}
# remotes::install_github("tjmahr/fillgaze")
```


In this post, I describe a recent case where I used rlang's [tidy
evaluation](http://rlang.tidyverse.org/articles/tidy-evaluation.html)
system to do some data-cleaning. This example is not particularly
involved, but it demonstrates is a basic but powerful idea: That we can
capture the expressions that a user writes, pass them around as data,
and make some `r emo::ji("dizzy")` magic `r emo::ji("sparkles")` happen.
This technique in R is called [*nonstandard
evaluation*](http://adv-r.had.co.nz/Computing-on-the-language.html).

## Strange eyetracking data

Last week, I had to deal with a file with some eyetracking data from a
sequence-learning experiment. The eyetracker records the participant's gaze
location at a rate of 60 frames per second---except for this weird file which
wrote out ~80 frames each second. In this kind of data, we have one row per
eyetracking sample, and each sample records a timestamp and the gaze location
:eyes: on the computer screen at each timestamp. In this particular dataset, we
have _x_ and _y_ gaze coordinates in pixels (both eyes averaged together,
`GazeX` and `GazeY`) or in screen proportions (for each eye in the `EyeCoord`
columns.)

```{r, message = FALSE, warning = FALSE}
library(dplyr)
library(ggplot2)
library(rlang)
# the data is bundled with an R package I wrote
# devtools::install_github("tjmahr/fillgaze")

df <- system.file("test-gaze.csv", package = "fillgaze") %>% 
  readr::read_csv() %>% 
  mutate(Time = Time - min(Time)) %>% 
  select(Time:REyeCoordY) %>% 
  round(3) %>% 
  mutate_at(vars(Time), round, 1) %>% 
  mutate_at(vars(GazeX, GazeY), round, 0)
df
```

In this particular eyetracking setup, offscreen looks are coded as negative gaze
coordinates, and what's extra weird here is that every second or third point is
incorrectly placed offscreen. We see that in the frequent -1920 values in
`GazeX`. Plotting the first few _x_ and _y_ pixel locations shows the 
pattern as well.


```{r missing-data-plot, fig.height = 3, fig.cap = "Offscreens looks occurred every two or three samples."}
p <- ggplot(head(df, 40)) + 
  aes(x = Time) + 
  geom_hline(yintercept = 0, size = 2, color = "white") + 
  geom_point(aes(y = GazeX, color = "GazeX")) +
  geom_point(aes(y = GazeY, color = "GazeY")) + 
  labs(
    x = "Time (ms)", 
    y = "Screen location (pixels)", 
    color = "Variable"
  )

p + 
  annotate(
    "text", x = 50, y = -200, 
    label = "offscreen", color = "grey20"
  ) + 
  annotate(
    "text", x = 50, y = 200, 
    label = "onscreen", color = "grey20"
  ) 
```

It is physiologically impossible for a person's gaze to oscillate so quickly and
with such magnitude (the gaze is tracked on a large screen display), so
obviously something weird was going on with the experiment software.

This file motivated me to develop a [general purpose package for interpolating
missing data in eyetracking experiments](https://github.com/tjmahr/fillgaze).
This package was always something I wanted to do, and this file moved it from 
the _someday_ list to the _today_ list. 

## A function to recode values in many columns as `NA`

The first step in handling this problematic dataset is to convert the offscreen
values into actual missing (`NA`) values). Because we have several columns of
data, I wanted a succinct way to recode values in multiple columns into `NA`
values.

First, we sketch out the _code we want to write_ when we're done.

```{r, eval = FALSE}
set_na_where <- function(data, ...) {
  # do things
}

set_na_where(
  data = df,
  GazeX = GazeX < -500 | 2200 < GazeX,
  GazeY = GazeY < -200 | 1200 < GazeY
)
```

That is, after specifying the `data`, we list off an arbitrary number of column
names, and with each name, we provide a rule to determine whether a value in
that column is offscreen and should be set to `NA`. For example, we want every
value in `GazeX` where `GazeX < -500` or `2299 < GazeX` is `TRUE` to be replaced
with `NA`.

### Bottling up magic spells

Lines of computer code are magic spells: We say the incantations and things
happen around us. Put more formally, the code contains expressions that are
evaluated in an environment.

```{r, error = TRUE}
hey <- "Hello!"
message(hey)

exists("x")

x <- pi ^ 2
exists("x")

print(x)

stop("what are you doing?")
```

In our function signature, `function(data, ...)`, the expressions are collected
in the special "dots" argument (`...`). In normal circumstances, we can view the
contents of the dots by storing them in a list. Consider:

```{r}
hello_dots <- function(...) {
  str(list(...))
}
hello_dots(x = pi, y = 1:10, z = NA)
```

But we not passing in regular data, but expressions that need to be evaluated in
a particular location. Below the magic words are uttered and we get an error
because they mention things that do not exist in the current environment.

```{r, error = TRUE}
hello_dots(GazeX = GazeX < -500 | 2200 < GazeX)
```

What we need to do is prevent these words from being uttered until the time and
place are right. **Nonstandard evaluation is a way of bottling up magic spells
and changing how or where they are cast**---sometimes we even change the magic
words themselves. We bottle up or _capture_ the expressions given by the user by
quoting them. `quo()` quotes a single expression, and `quos()` (plural) will
quote a list of expressions. Below, we capture the expressions stored in the
dots :speech_balloon: and then make sure that their names match column names in
the dataframe.

```{r, eval = TRUE}
set_na_where <- function(data, ...) {
  dots <- quos(...)
  stopifnot(names(dots) %in% names(data), !anyDuplicated(names(dots)))
  
  dots
  # more to come
}

spells <- set_na_where(
  data = df,
  GazeX = GazeX < -500 | 2200 < GazeX, 
  GazeY = GazeY < -200 | 1200 < GazeY
)
spells
```

I call these results `spells` because it just contains the expressions stored as
data. We can interrogate these results like data. We can query the names of the
stored data, and we can extract values (the quoted expressions).

```{r}
names(spells)
spells[[1]]
```

### Casting spells

We can cast a spell by evaluating an expression. To keep the incantation from
fizzling out, we specify that we want to evaluate the expression _inside_ of the
dataframe. The function `eval_tidy(expr, data)` lets us do just that: evaluate
an expression `expr` inside of some `data`.

```{r}
# Evaluate the first expression inside of the data
xs_to_set_na <- eval_tidy(spells[[1]], data = df)

# Just the first few bc there are 10000+ values
xs_to_set_na[1:20]
```

In fact, we can evaluate them all at once with by applying `eval_tidy()` on each
listed expression.

```{r}
to_set_na <- lapply(spells, eval_tidy, data = df)
str(to_set_na)
```

### Finishing touches

Now, the rest of the function is straightforward. Evaluate each `NA`-rule on 
the named columns, and then set each row where the rule is `TRUE` to `NA`.

```{r}
set_na_where <- function(data, ...) {
  dots <- quos(...)
  stopifnot(names(dots) %in% names(data), !anyDuplicated(names(dots)))
  
  set_to_na <- lapply(dots, eval_tidy, data = data)
  
  for (col in names(set_to_na)) {
    data[set_to_na[[col]], col] <- NA
  }
  
  data
}

results <- set_na_where(
  data = df,
  GazeX = GazeX < -500 | 2200 < GazeX, 
  GazeY = GazeY < -200 | 1200 < GazeY
)
results
```

Visually, we can see that the offscreen values are no longer plotted. Plus, we 
are told that our data now has missing values.

```{r no-offscreen-plots, fig.height = 3, fig.cap = "Offscreens are no longer plotted."}
# `plot %+% data`: replace the data in `plot` with `data`
p %+% head(results, 40)
```

One of the quirks about some eyetracking data is that during a blink, sometimes
the device will record the _x_ location but not the _y_ location. (I think this
happens because blinks move vertically so the horizontal detail can still be
inferred in a half-closed eye.) This effect shows up in the data when there are
more `NA` values for the _y_ values than for the _x_ values:

```{r}
count_na <- function(data, ...) {
  subset <- select(data, ...)
  lapply(subset, function(xs) sum(is.na(xs)))
}

count_na(results, GazeX, GazeY)
```

We can equalize these counts by running the function a second time with new rules.

```{r}
df %>% 
  set_na_where(
    GazeX = GazeX < -500 | 2200 < GazeX, 
    GazeY = GazeY < -200 | 1200 < GazeY
  ) %>% 
  set_na_where(
    GazeX = is.na(GazeY), 
    GazeY = is.na(GazeX)
  ) %>% 
  count_na(GazeX, GazeY)
```

Alternatively, we can do this all at once by using the same `NA`-filtering rule
on `GazeX` and `GazeY`.

```{r}
df %>% 
  set_na_where(
    GazeX = GazeX < -500 | 2200 < GazeX | GazeY < -200 | 1200 < GazeY, 
    GazeY = GazeX < -500 | 2200 < GazeX | GazeY < -200 | 1200 < GazeY
  ) %>% 
  count_na(GazeX, GazeY)
```

These last examples, where we compare different rules, showcases how nonstandard
evaluation lets us write in a very succinct and convenient manner and quickly
iterate over possible rules. Works like magic, indeed.


```{r, include = FALSE}
.parent_doc <- knitr::current_input()
```
```{r, child = "_R/_footer.Rmd"}
```
