---
title: "Untitled"
author: "Tristan Mahr"
date: "2024-05-30"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```



In this post, we go into the weeds. I describe a breakthrough I had in
how to compute marginal means from Bayesian mixed effects models with
correlated varying effects (that is, random slopes). 

The main takeaways for this post are that a transformed fixed effects
estimate is not the same as the population-average mean for logistic
regression models and we need to marginalize over random effects to get
that population-average mean.


```{r}
library(tidyverse)
d <- rtdists::speed_acc |> 
  tibble::as_tibble() |> 
  mutate(
    correct = as.character(response) == as.character(stim_cat),
    correct = as.numeric(correct),
    freq = frequency |> 
      as.character() |> 
      stringr::str_replace("nw_", "")
  )
d
a <- d |> 
  filter(!censor) |> 
  group_by(id, condition, stim_cat, frequency) |> 
  summarise(
    n_correct = sum(correct),
    n_trials = n(),
    n_incorrect = sum(!correct)
  ) |> 
  ungroup()

library(lme4)
m <- glmer(
  cbind(n_correct, n_trials - n_correct) ~ condition + (condition | id),
  family = binomial(),
  data = a
)
summary(m)
ggplot(a) + 
  aes(x = condition, y = n_correct / n_trials) + 
  # geom_point() +
  # geom_line(aes(group = id)) +
  stat_summary(aes(group = id)) +
  stat_summary(aes(group = id), geom = "line")

lattice::dotplot(ranef(m))

d |> 
  distinct(stim_cat, frequency)
d |> 
  distinct(stim, stim_cat, frequency)

d$stim_cat
d$response
d
ggplot(d) + aes(x = id, y = correct, color = condition) + stat_summary() + facet_wrap(~stim_cat)

```


## Data: A repeated measures experiment with non-normal data

I'll be using the `rtdists::speed_acc` dataset (Wagenmakers, Ratcliff, Gomez & McKoon, [2008](https://pmc.ncbi.nlm.nih.gov/articles/PMC2330283/); Heathcote & Love, [2012](https://pmc.ncbi.nlm.nih.gov/articles/PMC3425963/)).

```{r}
library(tidyverse)
data_lexdec <- rtdists::speed_acc |> 
  tibble::as_tibble() |> 
  filter(!censor) |> 
  mutate(
    correct = as.character(response) == as.character(stim_cat),
    correct = as.numeric(correct),
    freq = frequency |> 
      as.character() |> 
      stringr::str_replace("nw_", "")
  ) |> 
  select(id, block, condition, stim, stim_cat, response, correct, freq)
```

In this *lexical decision* experiment, participants were given a string
of letters onscreen and had to indicate whether the string was a word or
a nonword. (Try [an online
demo](https://lexicaldec.cognition.run/?demo=true) of a lexical decision
experiment to get a flavor of the task.) Half the time the string was a
word and half the time the string was a nonword, as recorded in the
`stimcat` variable. 

```{r}
data_lexdec |> 
  count(stim_cat)
```

> Participants were instructed to press the ‚Äò/‚Äô key with
their right index finger when they believed the presented
letter string to be an English word and to press the ‚Äòz‚Äô
key with their left index finger when they did not believe
the presented letter string to be an English word. In the
accuracy blocks, each of which was preceded by the message "Try to respond accurately", the feedback message
"ERROR" was presented [...] after every erroneous response. In the speed blocks, each of which was
preceded by the message "Try to respond fast", the feed-
back message ‚Äò‚ÄòTOO SLOW‚Äô‚Äô was presented [...]
after every trial for which the response latency exceeded
750 ms. In both the accuracy blocks and the speed
blocks, anticipatory responding was discouraged by
the 800 ms presentation of the feedback message
‚Äò‚ÄòTOO FAST‚Äô‚Äô after every trial for which the response
latency was shorter than 200 ms. The response‚Äìstimulus
interval was 150 ms.

Seventeen participants each completed 20 blocks of trials. In each
block, they were instructed to aim for *accuracy* or *speed*
(`condition`). If they were inaccurate on *accuracy* trials, they got an
ERROR message, and if they took too long on speed trials, they got a TOO
SLOW message.

```{r}
data_lexdec |> 
  count(condition, stim_cat)
```

The real words varied in frequency (`freq`: high, low and very low), and
the nonwords were created by taking real words and randomly replacing
the vowels with other vowels (except for the U in QU). We can talk about
"high frequency nonwords" if the source of the nonword was a high
frequency real word.

```{r}
data_lexdec |> 
  count(condition, stim_cat, freq)
```

Thus, everything is neatly balanced by design but some bad trials had to be
discarded so we don't have exactly balanced *n*s.

Given this design, we can imagine some important questions things we might 
want to explore:

- Are nonwords easier than real words?
- Are low frequency words harder than high frequency words? 
- Do speed and accuracy compete with each other?


## Starting simple: Accuracy on real words for speed trials

Let's consider the average accuracy for real words on the *speed* üèÉ‚Äç‚ôÄÔ∏è
trials. 

```{r}
data_by_condition <- data_lexdec |> 
  group_by(id, condition, stim_cat) |> 
  summarise(
    n_correct = sum(correct),
    n_trials = n(),
    n_incorrect = sum(!correct)
  ) |> 
  ungroup() 

data_real_speed <- data_by_condition |> 
  filter(condition == "speed", stim_cat == "word")

data_real_speed
```

We will fit a mixed effects logistic regression model for this dataset.
Formally, the observed data is the number of successes $y_i$ in $n_i$
trials for each participant $i$. We want to estimate $p_i$, the
probability of success for each participant. Spelled out formally, we
have:

$$
\begin{align*}
y_i &= \operatorname{Binomial}(n_i~\text{trials}, p_i) & \\
p_i &= \operatorname{inv\_logit}(\eta_i) & \\
\eta_i &= b_0 + \alpha_{i} & \\
\alpha_{i} &\sim \operatorname{Normal}(0, \sigma) &\\
i &: \text{participant index} &\\
y &: \text{observed number of successes} &\\
p &: \text{probability of success} &\\
\eta &: \text{linear model on the logit scale}\\
b_0 &: \text{intercept, logit of success for typical participant} &\\
\alpha_i &: \text{participant's adjustment from the typical value} &\\
\sigma &: \text{between-participant variability} &\\
\end{align*}
$$

Each participant has their personal probability of correctly choosing word or 
nonword, $p_i$. This probability is the **conditional mean** or 
**subject-specific mean**. The word *conditional* is there to remind us that 
there is a conditional probability or conditional expectation at play.

$$
\operatorname{Pr}(\text{correct} \mid \text{participant}_i) \\
\operatorname{E}(\text{correct} \mid \text{participant}_i, n~\text{trials})
$$


But if we remove that conditional part, we have a **marginal mean** or
**population mean** or **population-averaged mean**:

$$
\operatorname{Pr}(\text{correct}) \\
\operatorname{E}(\text{correct} \mid n~\text{trials})
$$

And we can remove that conditional part by averaging (or marginalizing) over all of the participants. See the [law of total expectation](https://en.wikipedia.org/wiki/Law_of_total_expectation#Informal_proof) with $\operatorname{E}(X) = \operatorname{E}(\operatorname{E}(X \mid Y))$ or the [definition of a marginal probability](https://en.wikipedia.org/wiki/Marginal_distribution). **The purpose of this post is demonstrate various ways to achieve this marginalization.**


Now, let's fit this model.

```{r}
model_real_speed <- glmer(
  cbind(n_correct, n_incorrect) ~ 1 + (1 | id),
  family = binomial(),
  data = data_real_speed
)
summary(model_real_speed)
```


The intercept corresponds to $b_0$, the estimated accuracy for a "typical" participant, and I emphasize the word *typical* because this participant's estimate is actually a conditional estimate. It is the estimate accuracy for a participant whose $\alpha$ is 0.

$$
\begin{align*}
p_i &= \operatorname{inv\_logit}(b_0 + \alpha_i)  & \\
\alpha_\text{typical} &= 0 &\\
p_\text{typical} &= \operatorname{inv\_logit}(b_0) & \\
\end{align*}
$$

The accuracy estimates for the observed participants vary around this typical
participant under a normal distribution on the logit scale. The SD of
this normal distribution, $\sigma$ is given in the model's random
effects summary.

At this point, we can estimate a population-average or marginal accuracy. 

```{r}
logit_typical <- fixef(model_real_speed)["(Intercept)"] |> unname()
# sigma(model_real_speed)
logit_sigma <- model_real_speed |> 
  VarCorr() |> 
  getElement("id") |> 
  attr("stddev") |> 
  unname()

logit_typical
logit_sigma


plogis(logit_typical)

sim_participants <- rnorm(1000, logit_typical, logit_sigma)
plogis(sim_participants) |> mean()
```











<!-- Let's hammer out the terminology right away. There is a population of  -->
<!-- participants, and they each have their own probability of correctly choosing *word* or *nonword*.  -->


```{r}

tibble(
  x = qnorm(ppoints(100), 2, 1),
  y = plogis(x),
  x_m = mean(x),
  y_m = mean(y),
) |> 
  ggplot() + geom_point(aes(x = x, y = y)) +
  geom_vline(aes(xintercept = x_m)) +
  geom_hline(aes(yintercept = y_m)) +
  geom_density(aes(x = x, y = after_stat(scaled) / 5)) + 
  geom_density(aes(y = y, x = after_stat(scaled) - 1), orientation = "y")
  

logitnorm_mean <- wisclabmisc::logitnorm_mean
means <- ppoints(200)
logits <- qlogis(means)
sd <- .5

p <- expand.grid(means = means, sd = c(.1, .25, .5, .75, 1, 1.5, 2)) |> 
  mutate(
    logits = qlogis(means), 
    y = logitnorm_mean(logits, sd)
  )
ggplot(p) + aes(x = means, y = y) + geom_line(aes(group = sd, color = sd))
tibble(
  x = means,
  y = logitnorm_mean(logits, sd)
) 


# |> 
#   ggplot() + geom_line(aes(x,y)) + geom_abline()


ggplot() + 
  stat_function(
    fun = logitnorm::dlogitnorm, 
    args = list(mu = 0, sigma = 5)
  )

logitnorm::dlogitnorm()


ggplot()
```


## Easy case: logitnorm




```{r}
data_real_speed <- a |> 
  filter(stim_cat == "word", condition == "speed")

model_real_speed <- glmer(
  cbind(n_correct, n_incorrect) ~ 1 + (1 | id),
  family = binomial(),
  data = data_real_speed
)
summary(model_real_speed)
```


The fixed effects here describe a *statistically average* or
*statistically typical* participant. We need to emphasize the word
*statistically* here because this value only makes sense in the context
of this data and this model. The fixed effects predictions here are
conditional, or subject-specific, predictions. They happen to be the
prediction for a participant whose $\alpha_i = 0$.

To convert from a conditional prediction to a marginal one, we can
simulate new participants by drawing them from a normal distribution.

```{r}
inv_logit <- brms::inv_logit_scaled

sigma <- VarCorr(model_real_speed) |> getElement("id") |> attr("stddev")

new_alphas <- rnorm(1000, 0, sigma)


means_real_speed <- list()

means_real_speed$typical <- fixef(model_real_speed) |> 
  inv_logit() |> 
  unname()

means_real_speed$marginal_rnorm <- 
  (fixef(model_real_speed) + new_alphas) |> 
  inv_logit() |> 
  mean()
```

The logitnorm R package can do this calculation using numerical
integration (as opposed to simulating new participants):

```{r}
means_real_speed$marginal_logitnorm <- model_real_speed |> 
  fixef() |> 
  logitnorm::momentsLogitnorm(mu = _, sigma = sigma) |> 
  getElement("mean")
```

In my research for this post, I found the following approximation:

```{r}
var_logistic <- ((pi ^ 2) / 3) * (15 / 16)
b_pa <- fixef(model_real_speed) / sqrt(((sigma ^ 2) + var_logistic) / var_logistic)
means_real_speed$marginal_approx <- unname(inv_logit(b_pa))
```

[Demidenko (2004, 2013)](https://www.eugened.org/mixed-models) also provides this approximation:

```{r}
adjustment <- (sigma ^ 2) / 1.7 ^ 2
adjustment <- 1 / sqrt(1 + adjustment)
b_pa <- fixef(model_real_speed) * adjustment
means_real_speed$marginal_approx_2 <- unname(inv_logit(b_pa))
```





Another kind of mean we might want is the average conditional mean:

```{r}
means_real_speed$avg_conditional <- model_real_speed |> 
  coef() |> 
  getElement("id") |> 
  as.matrix() |> 
  inv_logit() |> 
  mean()
```

```{r}
means_real_speed
```


Let's move on to a random-slope model.


```{r}
data_real <- a |> 
  filter(stim_cat == "word")

model_real <- glmer(
  cbind(n_correct, n_incorrect) ~ condition + (condition | id),
  family = binomial(),
  data = data_real
)
summary(model_real)
```

Here, the random effects are correlated, so to simulate new participants, we 
need to sample from the multivariate normal distribution. logitnorm cannot help 
us at this point.


```{r}
m <- matrix(c(1, 0, 1, 1), nrow = 2)

sd <- VarCorr(model_real) |> getElement("id") |> attr("stddev")
cor <- VarCorr(model_real) |> getElement("id") |> attr("correlation")

sim <- faux::rnorm_multi(
  n = 1000,
  mu = fixef(model_real),
  sd = sd,
  r = cor,
  as.matrix = TRUE
)
means2 <- list()

means2$marginal_rnorm <- inv_logit(sim %*% m) |> 
  colMeans() |> setNames(c("accuracy", "speed"))

# sim[,2] <- sim[,1] + sim[,2]

means2$typical <- inv_logit(fixef(model_real) %*% m) |> 
  as.vector() |> 
  setNames(c("accuracy", "speed"))

```

Again, with the average conditional mean.

```{r}
subj <- coef(model_real) |> getElement("id") |> as.matrix()

means2$avg_conditional <- inv_logit(subj %*% m) |> 
  colMeans() |> 
  setNames(c("accuracy", "speed"))
```


```{r}
means2
```

## Bayesian models

The above examples were manageable and straightforward. But what about in a 
Bayesian model where instead of a single correlation matrix we have a whole 
posterior distribution of them (or rather, 4000 draws from the posterior distribution)?

The rvar (random variable) datatype from the posterior package can help us 
tremendously here because it lets you treat the abstract over draws, in a way. This is hard to explain.

```{r}

library(brms)
f <- bf(
  n_correct | trials(n_trials) ~ condition + (condition | id), 
  family = binomial()
)
p <- c(
  set_prior("normal(0, 2)", class = "Intercept"),
  set_prior("normal(0, 1)", class = "b"),
  set_prior("normal(0, 1)", class = "sd"),
  set_prior("lkj(2)", class = "cor")
)
validate_prior(p, f, data = data_real)


bayes_real <- brm(
  f, 
  data_real, 
  prior = p, 
  backend = "cmdstanr", 
  file = "model_real"
)
```


Let's do the fixed effects conditional means first. By default,
`fixef()` summarize the posterior distribution of the fixed effects for
us.

```{r}
library(posterior)
set_colnames <- `colnames<-`

mean_bayes <- list()

fixef(bayes_real)

bayes_fixef <- bayes_real |> 
  fixef(summary = FALSE) |> 
  rvar(dim = 2)
bayes_fixef

mean_bayes$typical <- inv_logit(bayes_fixef %**% m) |> 
  # matrix multiplications gives 1 x 2 matrix rvar so 
  # reset two be a length-two vector rvar
  rvar(dim = 2) |>  
  setNames(c("accuracy", "speed")) 
mean_bayes
```

`bayes_fixef` is a two-variable rvar on 4000 draws. We would normally
treat it as a 4000 x 2 matrix (draws x variables) but as an rvar, we get
to mostly treat it like the 2-element vector from earlier.

One twist here is that rvar uses `%**%` for matrix multiplication
instead of `%*%`.


Now, for the next step up in difficulty, let's take the average
conditional mean. As in the lme4 case, `coef()` will return
subject-specific parameters and we can matrix-multiply them by the
simple design matrix to get the fitted values for each condition.

```{r}
coef_rvar <- bayes_real |> 
  coef(summary = FALSE) |> 
  getElement("id") |> 
  rvar()

bayes_ss <- inv_logit(coef_rvar %**% m)

colnames(bayes_ss) <- c("accuracy", "speed")
bayes_ss

bayes_ss
```

At this point, we have 4000 x 17 x 2 condition means and we want 4000
x 2 condition means by averaging over the 17 participants in each draw. 
```{r}
mean_bayes$avg_conditional <- bayes_ss |> 
  rvar_apply(.margin = 2, rvar_mean)

mean_bayes


```

The code is completely analogous to what we would write in for a regular matrix.

```{r}
# mean <- matrix |> apply(margin = 2, mean)
```


Finally, we can tell rvar to just do it's thing.

```{r}
# m <- matrix(c(1, 0, 1, 1), nrow = 2)
bayes_fixef

bayes_sd <- bayes_real |> 
  VarCorr(summary = FALSE) |> 
  purrr::pluck("id", "sd") |> 
  rvar()

bayes_cor <- bayes_real |> 
  VarCorr(summary = FALSE) |> 
  purrr::pluck("id", "cor") |> 
  rvar()

sim <- rdo(
  faux::rnorm_multi(
    n = 1000,
    mu = bayes_fixef,
    sd = bayes_sd,
    r = bayes_cor,
    as.matrix = TRUE
  )
)
head(sim)
```


```{r}
mean_bayes$marginal <- inv_logit(sim %**% m) |> rvar_apply(2, rvar_mean)
mean_bayes
```





```{r}
aa <- a |> 
  filter(stim_cat == "word")

aa_data <- aa

m <-
summary(m)
conditional_effects(m)


ggplot(aa_data) + 
  aes(x = condition, y = n_correct / n_trials) +
  geom_line(aes(group = id), stat = "summary")
summary(m)
```



```{r}
d |> 
  filter(condition == "accuracy") |> 
  ggplot() + 
  aes(x = freq, y = correct) + 
  stat_summary(aes(color = stim_cat, group = id:stim_cat), geom = "line", position = position_jitter(width = .1, height = 0))
```


```{r}
a <- d |> 
  filter(!censor) |> 
  group_by(id, condition, stim_cat, frequency, freq) |> 
  summarise(
    n_correct = sum(correct),
    n_trials = n()
  ) |> 
  ungroup()
library(lme4)
p <- glmer(
  cbind(n_correct, n_trials - n_correct) ~ freq  + (freq | id),
  family = binomial(),
  data = a |> filter(condition == "accuracy", stim_cat == "word")
)
summary(p)
```

```{r}
library(brms)
cmdstanr::check_cmdstan_toolchain()

data <- a |> filter(condition == "accuracy", stim_cat == "word") |> 
  mutate(freq = ordered(freq, c("high", "low", "very_low")))
f <- bf(
  n_correct | trials(n_trials) ~ mo(freq) + (mo(freq) | id), 
  family = binomial()
)
f
p <- c(
  set_prior("normal(0, 2)", class = "Intercept"),
  set_prior("normal(0, 1)", class = "b"),
  set_prior("normal(0, 1)", class = "sd"),
  set_prior("lkj(2)", class = "cor")
  
)
validate_prior(p, f, data = data)

m <- brm(f, data, prior = p, backend = "cmdstanr")
summary(m)
conditional_effects(m)
```

Instead, here's the recipe,  using rvar.

```{r}
library(posterior)

m$basis
?mo
fixef(m)
m
new_participant <- data |> 
  distinct(freq) |> 
  mutate(id = "fake", n_trials = 1, n_correct = 0) 


posterior_summary(m, variable = "simo_mofreq1")


posterior_epred(m, new_participant, re_formula = NA) |> rvar()

r <- as_draws_rvars(m, c("b_Intercept", "simo_mofreq1", "bsp_mofreq"))

# intercept (high frequency)
brms::inv_logit_scaled(r$b_Intercept)

# low frequency
brms::inv_logit_scaled(
  r$b_Intercept + 
    2 * r$bsp_mofreq * r$simo_mofreq1[1]
)

# very low frequency
brms::inv_logit_scaled(
  r$b_Intercept + 
    2 * r$bsp_mofreq * r$simo_mofreq1[1] +
    2 * r$bsp_mofreq * r$simo_mofreq1[2]
)
# 2 is the number of cut points (or the number of levels minus 1)



rvar(posterior_epred(
  m, 
  newdata = new_participant, 
  re_formula = NA
))

coef(m, pars = "mofreq1")
str(coef(m))
posterior_epred(m, new_participant, resp = "mofreq1", re_formula = NA)
fixef()
m
coef(m)
VarCorr(m, summary = FALSE, )[["id"]][["cov"]] |> rvar()
rvar()
```



